# Mentor Vision Example

```elixir
Mix.install([:mentor])
```

## Using Multimodal Capabilities with Mentor

This example demonstrates how to use Mentor with vision-capable models from Google Gemini and OpenAI.

## Creating a Schema for Image Analysis

First, let's define a schema for image analysis that will structure the model's response:

```elixir
defmodule ImageAnalysis do
  @moduledoc """
  A schema for image content analysis.

  ## Fields
  
  - `description`: A detailed description of what is visible in the image
  - `objects`: A list of objects/entities detected in the image
  - `text_content`: Any text visible in the image (empty string if none)
  - `colors`: The predominant colors in the image
  """

  use Ecto.Schema
  use Mentor.Ecto.Schema

  import Ecto.Changeset

  @primary_key false
  embedded_schema do
    field :description, :string
    field :objects, {:array, :string}
    field :text_content, :string
    field :colors, {:array, :string}
  end

  @impl true
  def changeset(%__MODULE__{} = analysis, %{} = attrs) do
    analysis
    |> cast(attrs, [:description, :objects, :text_content, :colors])
    |> validate_required([:description, :objects, :colors])
    |> validate_length(:description, min: 10)
    |> validate_length(:objects, min: 1)
    |> validate_length(:colors, min: 1)
  end
end
```

## Using Google Gemini for Image Analysis

Now, let's create a function that analyzes images using Google Gemini models:

```elixir
defmodule GeminiVision do
  @moduledoc """
  Uses Google Gemini to analyze images
  """

  alias Mentor.LLM.Adapters.Gemini

  @doc """
  Analyzes an image using Google Gemini Vision models.
  
  Parameters:
  - binary: The binary image data
  - options: Configuration options for the analysis
  """
  @spec analyze_image(binary(), keyword()) :: {:ok, struct()} | {:error, term()}
  def analyze_image(binary, opts \\ []) do
    schema = opts[:schema] || ImageAnalysis
    model = opts[:model] || "gemini-2.0-pro-vision"
    max_retries = opts[:max_retries] || 1
    temperature = opts[:temperature] || 0.2
    prompt = opts[:prompt] || "Analyze this image in detail"
    b64_encoded_image = Base.encode64(binary)
    
    Gemini
    |> Mentor.start_chat_with!(schema: schema, max_retries: max_retries)
    |> Mentor.configure_adapter(
      api_key: System.fetch_env!("GEMINI_API_KEY"),
      temperature: temperature,
      model: model
    )
    |> Mentor.append_message(%{
      role: "user",
      content: [
        %{type: "text", text: prompt},
        %{
          type: "image_base64",
          data: b64_encoded_image,
          mime_type: "image/jpeg"
        }
      ]
    })
    |> Mentor.complete()
  end
end
```

## Using OpenAI for Image Analysis

For comparison, here's the equivalent using OpenAI vision models:

```elixir
defmodule OpenAIVision do
  @moduledoc """
  Uses OpenAI to analyze images
  """

  alias Mentor.LLM.Adapters.OpenAI

  @doc """
  Analyzes an image using OpenAI Vision models.
  
  Parameters:
  - binary: The binary image data
  - options: Configuration options for the analysis
  """
  @spec analyze_image(binary(), keyword()) :: {:ok, struct()} | {:error, term()}
  def analyze_image(binary, opts \\ []) do
    schema = opts[:schema] || ImageAnalysis
    model = opts[:model] || "gpt-4o"
    max_retries = opts[:max_retries] || 1
    temperature = opts[:temperature] || 0.2
    prompt = opts[:prompt] || "Analyze this image in detail"
    b64_encoded_image = Base.encode64(binary)
    
    OpenAI
    |> Mentor.start_chat_with!(schema: schema, max_retries: max_retries)
    |> Mentor.configure_adapter(
      api_key: System.fetch_env!("OPENAI_API_KEY"),
      temperature: temperature,
      model: model
    )
    |> Mentor.append_message(%{
      role: "user",
      content: [
        %{type: "text", text: prompt},
        %{
          type: "image_url",
          image_url: %{
            url: "data:image/jpeg;base64,#{b64_encoded_image}"
          }
        }
      ]
    })
    |> Mentor.complete()
  end
end
```

## Example Usage

Here's how you would use these modules to analyze an image:

```elixir
# Read an image file
{:ok, image_data} = File.read("path/to/your/image.jpg")

# Analyze with Gemini
{:ok, gemini_analysis} = GeminiVision.analyze_image(image_data)

# Analyze with OpenAI
{:ok, openai_analysis} = OpenAIVision.analyze_image(image_data)

# Compare the results
IO.puts("Gemini description: #{gemini_analysis.description}")
IO.puts("OpenAI description: #{openai_analysis.description}")
```

This example demonstrates Mentor's flexibility in working with different vision models while providing consistent structured outputs through Ecto schemas.